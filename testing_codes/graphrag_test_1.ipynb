{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd7f1531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ca3583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDFs from: ./data/\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "\n",
    "data_dir = \"./data/\"\n",
    "print(f\"Loading PDFs from: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42575c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' data ingestion\\n\\n1. read all pdfs in data_dir\\n2. \\n3. \\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" data ingestion\n",
    "\n",
    "1. read all pdfs in data_dir\n",
    "2. \n",
    "3. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e99e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# doc = fitz.open(\"/home/fuths/projects/graphrag_weaviate_1/data/Beyond Backpropagation Exploring Innovative Algorithms for.pdf\")\n",
    "\n",
    "# for page_num, page in enumerate(doc, start=1):\n",
    "#     text = page.get_text(\"text\")  # modes: \"text\", \"blocks\", \"dict\", \"json\", \"html\"\n",
    "#     print(f\"--- Page {page_num} ---\")\n",
    "#     print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcabef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "file_path = \"/home/fuths/projects/graphrag_weaviate_1/data/Beyond Backpropagation Exploring Innovative Algorithms for.pdf\"\n",
    "loader = PyMuPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0553f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89745d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 200 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84a6093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in all_splits:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b439e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding models\n",
    "\n",
    "# embedding model\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040f5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb\n",
    "\n",
    "import weaviate\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "\n",
    "weaviate_client = weaviate.connect_to_local()\n",
    "\n",
    "vectorstore = WeaviateVectorStore.from_documents(\n",
    "    client=weaviate_client,\n",
    "    documents=all_splits,\n",
    "    embedding=embedding_model,\n",
    "    index_name=\"graphrag_v2_test1\",  # name your class\n",
    ")\n",
    "\n",
    "# retriver = vectorstore.as_retriever(search_type=\"mmr\")  # max marginal relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4abfa6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "complexity (MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100), the scalability and\n",
      "practical applicabil...\n",
      "\n",
      "Document 2:\n",
      "complexity (MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100), the scalability and\n",
      "practical applicabil...\n",
      "\n",
      "Document 3:\n",
      "versions or fixed training durations, the author conducted all experiments within a consistent,\n",
      "mode...\n",
      "\n",
      "Document 4:\n",
      "versions or fixed training durations, the author conducted all experiments within a consistent,\n",
      "mode...\n"
     ]
    }
   ],
   "source": [
    "query = \"what training methods are investigated?\"\n",
    "docs = vectorstore.similarity_search(query)\n",
    "\n",
    "# Print the first 100 characters of each result\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nDocument {i + 1}:\")\n",
    "    print(doc.page_content[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3e7a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc02511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'versions or fixed training durations, the author conducted all experiments within a consistent,\\nmodern software environment (detailed in Section 3.8) and used early stopping to determine\\nthe effective training duration, thus ensuring an equitable comparison of algorithms on contem-\\nporary hardware.\\n18'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(query)[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f629988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa models\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:latest\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adccab10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Programming is the process of designing, writing, testing, and maintaining the instructions that a computer follows to perform a specific task or set of tasks. These instructions, known as \"code,\" are written in one or more programming languages, which are used to communicate with computers.\\n\\nProgramming involves using a combination of logic, problem-solving skills, and creativity to write code that can be executed by a computer. The ultimate goal of programming is to create software, apps, websites, games, and other digital products that can perform specific tasks or provide useful services to users.\\n\\nSome common aspects of programming include:\\n\\n1. **Writing code**: Using a programming language to write instructions that the computer can understand.\\n2. **Problem-solving**: Identifying problems and developing solutions using code.\\n3. **Debugging**: Finding and fixing errors in the code to ensure it works correctly.\\n4. **Testing**: Verifying that the code produces the desired output or behavior.\\n5. **Maintenance**: Updating, modifying, or extending existing code to keep it relevant and functional.\\n\\nProgramming can be applied to a wide range of fields, including:\\n\\n1. **Web development**: Building websites, web applications, and mobile apps using programming languages like HTML, CSS, JavaScript, and server-side languages like PHP, Ruby, and Python.\\n2. **Mobile app development**: Creating mobile apps for Android and iOS devices using programming languages like Java, Swift, and Kotlin.\\n3. **Game development**: Designing and building games for PCs, consoles, or mobile devices using programming languages like C++, Java, and Python.\\n4. **Artificial intelligence (AI) and machine learning (ML)**: Developing algorithms and models that enable computers to learn from data and make decisions autonomously.\\n5. **Data analysis and science**: Using programming languages like R, Python, and SQL to analyze and interpret complex data sets.\\n\\nOverall, programming is a fundamental skill in the digital age, enabling individuals to create innovative solutions, automate tasks, and solve complex problems using technology.', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-11-05T22:14:21.728331512Z', 'done': True, 'done_reason': 'stop', 'total_duration': 30519898055, 'load_duration': 5549880784, 'prompt_eval_count': 40, 'prompt_eval_duration': 755821266, 'eval_count': 403, 'eval_duration': 24208469622, 'model_name': 'llama3.2:latest', 'model_provider': 'ollama'}, id='lc_run--79869d0c-ea14-4ba3-ade5-639866711867-0', usage_metadata={'input_tokens': 40, 'output_tokens': 403, 'total_tokens': 443})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that answers the following question.\",\n",
    "    ),\n",
    "    (\"human\", \"what is programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38d1b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cypher models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92bc4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c98a1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph db\n",
    "\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "graph = Neo4jGraph(url=\"bolt://localhost:7687\", username=\"neo4j\", password=\"test1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e3a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out custom note relation extraction\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an expert at extracting nodes and relations from documents. \n",
    "    you have to extract nodes and relations from the document provided.\n",
    "    the nodes should be the key concepts, entities, or ideas present in the document.\n",
    "    provide them with appropriate labels.\n",
    "    the relations should describe how these nodes are connected or related to each other.\n",
    "\n",
    "    try and reuse labels for nodes wherever possible.\n",
    "    provide the output in json format \n",
    "    \n",
    "    Here is the document: \n",
    "    {document}\n",
    "\n",
    "    \"\"\",\n",
    "    input_variables=[\"document\"],\n",
    ")\n",
    "\n",
    "\n",
    "node_relation_extractor = prompt | llm | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df4d57d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  the nodes should be the key concepts, entities, or ideas present in the document.\\nprovide them with appropriate labels.\\n  the relations should describe how these nodes are connected or related to each other.\\n\\n\\n\\n\\n  provide the output in json format\\nas shown below:\\n    {{\\n        \"nodes\": [\\n            {{\"id\": \"node1\", \"label\": \"Node Label 1\", \"properties\": {{\"property1\": \"value1\", \"property2\": \"value2\"}}}},\\n            {{\"id\": \"node2\", \"label\": \"Node Label 2\", \"properties\": {{\"property1\": \"value1\", \"property2\": \"value2\"}}}}\\n        ],\\n        \"relations\": [\\n            {{\"from\": \"node1\", \"to\": \"node2\", \"type\": \"RELATION_TYPE\", \"properties\": {{\"property1\": \"value1\"}}}}\\n        ]\\n    }}\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "  the nodes should be the key concepts, entities, or ideas present in the document.\n",
    "provide them with appropriate labels.\n",
    "  the relations should describe how these nodes are connected or related to each other.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  provide the output in json format\n",
    "as shown below:\n",
    "    {{\n",
    "        \"nodes\": [\n",
    "            {{\"id\": \"node1\", \"label\": \"Node Label 1\", \"properties\": {{\"property1\": \"value1\", \"property2\": \"value2\"}}}},\n",
    "            {{\"id\": \"node2\", \"label\": \"Node Label 2\", \"properties\": {{\"property1\": \"value1\", \"property2\": \"value2\"}}}}\n",
    "        ],\n",
    "        \"relations\": [\n",
    "            {{\"from\": \"node1\", \"to\": \"node2\", \"type\": \"RELATION_TYPE\", \"properties\": {{\"property1\": \"value1\"}}}}\n",
    "        ]\n",
    "    }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f85fbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "To ensure a fair and insightful analysis, a robust comparative framework was established.\n",
      "Each alternative algorithm was implemented on its native architecture (MLPs for FF and\n",
      "MF, a CNN for CaFo) and systematically compared against an equivalent model trained\n",
      "with BP. Critically, this methodology mandates comprehensive hyperparameter optimiza-\n",
      "tion for all algorithms using Optuna, coupled with consistent early stopping criteria based\n",
      "on validation performance, thereby ensuring that all comparisons are conducted between\n",
      "optimally tuned models.\n",
      "The investigation culminates in a significant finding: The Mono-Forward (MF) algo-\n",
      "rithm not only competes with, but consistently surpasses backpropagation in classification\n",
      "accuracy on its native MLP architectures. This superior generalization arises from the al-\n",
      "gorithmâ€™s ability to converge to a more favorable minimum in the validation loss landscape,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'AIMessage' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(all_splits[\u001b[32m1\u001b[39m].page_content)\n\u001b[32m      5\u001b[39m docs = node_relation_extractor.invoke(all_splits[\u001b[32m1\u001b[39m].page_content)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(docs,\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'AIMessage' has no len()"
     ]
    }
   ],
   "source": [
    "print(len(all_splits))\n",
    "print(all_splits[1].page_content)\n",
    "\n",
    "\n",
    "docs = node_relation_extractor.invoke(all_splits[1].page_content)\n",
    "print(len(docs))\n",
    "print(docs,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e611c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'id': '1', 'label': 'Algorithm'}, {'id': '2', 'label': 'Model'}, {'id': '3', 'label': 'Hyperparameter Optimization'}, {'id': '4', 'label': 'Early Stopping Criteria'}, {'id': '5', 'label': 'Validation Performance'}, {'id': '6', 'label': 'Optimization Methodology'}, {'id': '7', 'label': 'Mono-Forward Algorithm'}, {'id': '8', 'label': 'Backpropagation'}], 'relations': [{'source': '1', 'target': '2', 'relation': 'Implemented On'}, {'source': '3', 'target': '5', 'relation': 'Optimized For'}, {'source': '4', 'target': '5', 'relation': 'Based On'}, {'source': '6', 'target': '1,2,7,8', 'relation': 'Compared Against'}, {'source': '7', 'target': '8', 'relation': 'Competes With'}, {'source': '7', 'target': '5', 'relation': 'Surpasses In Classification Accuracy'}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7120ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865a32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b461555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add nodes and relations to the graph database\n",
    "\n",
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "# import time\n",
    "\n",
    "# graph_transformer = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     # allowed_nodes=[\"Concept\"],\n",
    "#     # node_properties=[\"\"],\n",
    "#     # allowed_relationships=[\"AUTHORED\", \"\", \"RELATED_TO\"],\n",
    "# )\n",
    "# print(\"1\")\n",
    "\n",
    "# graph_documents = []\n",
    "# for i,doc in enumerate(all_splits):\n",
    "#     stime = time.time()\n",
    "#     # Process one document at a time\n",
    "#     graph_doc = graph_transformer.convert_to_graph_documents([doc])\n",
    "#     graph_documents.extend(graph_doc)\n",
    "#     print(f\"end of chunk, time taken: {time.time() - stime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73b5f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # querying graphdb\n",
    "\n",
    "# from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     llm=llm,\n",
    "#     graph=graph,\n",
    "#     verbose=True,\n",
    "#     return_intermediate_steps=True,\n",
    "#     allow_dangerous_requests=True,\n",
    "# )\n",
    "\n",
    "# chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
